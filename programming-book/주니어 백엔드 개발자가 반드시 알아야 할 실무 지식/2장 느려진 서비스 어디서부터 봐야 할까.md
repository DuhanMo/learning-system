# 2장. 느려진 서비스, 어디서부터 봐야 할까

## 처리량과 응답 시간

### 응답 시간

하나의 API 요청을 처리하는데 걸리는 전체 시간의 구성
1. API 요청(: 서버에 연결 - 서버로 데이터 전송)
2. SQL 실행, 응답 생성 등(: 서버 실행)
3. API 응답(: 클라이언트로 데이터 전송)

DB 연동과 API 연동시간이 응답시간의 가장 큰 비율을 차지 

### 처리량

- TPS: Transaction Per Seconds 
  - 초당 완료된 요청 수
- 최대TPS: 시스템이 처리할 수 있는 최대 요청 수

## 서버 성능 개선 기초

### 병목 지점

서비스 초기에서 트래픽이 증가 하면서 발생하는 문제
1. 순간적으로 모든 사용자 요청에 대한 응답 시간이 심각하게 느려진다
2. 서버를 재시작하면 잠시 괜찮다가 다시 응답 시간이 늘어나는 현상이 반복된다
3. 트래픽이 줄어들 때 까지 심각한 상황이 계속된다

TPS를 높이기 위해선 병목 지점을 파악하고 해결해야 한다.


### 수직 확장과 수평 확장

급한불을 끄기 위해선 수직확장을 한다. 즉각적인 효과를 얻을 수 있지만 비용문제가 크고 언젠간 다시 성능문제가 발생한다.

서버를 추가로 투입해 TPS를 높일 수 있으며 이를 수평 확장이라고 한다.

다만, DB가 문제일 경우 서버를 늘리면 DB 부하가 커지기 때문에 DB나 외부 API 성능에 문제가 되지 않는 선에서 수평 확장을 해야 효과가 있다.


### DV 커넥션 풀

DB를 사용하기 위한 단계
1. DB에 연결한다
2. 쿼리를 실행한다
3. 사용이 끝나면 연결을 종료한다

이 때, DB에 연결하고 종료하는 작업이 리소스를 많이 차지하므로, DB 커넥션 풀을 사용한다.

애플리케이션이 부팅될 때 DB와 커넥션을 맺고 이를 풀로 관리한다.

커넥션 풀의 주요한 설정 3가지.
1. 커넥션 풀 크기
2. 풀에 커넥션이 없을 때 커넥션을 구할 때까지 대기할 시간
3. 커넥션의 유지 시간(최대 유휴 시간, 최대 유지 시간)

#### 설정1. 커넥션 풀 크기

일반적으로 트래픽은 증가했다가 감소하는 패턴을 보인다. 커넥션 풀 크기를 설정하면 이에 맞게 트래픽이 적을 땐 최소크기, 트래픽이 많을 때에는 최대크기로 유지할 수 있다.

> 트래픽이 순간적으로 급증할 땐 커넥션 풀의 최소 크기를 최대 크기에 맞추는 것이 좋다. 트래픽이 증가할 때 DB 연결 시간도 성능 저하의 주요 원인이 될 수 있기 때문이다.

#### 설정2. 커넥션 대기 시간

- 대기시간: 풀에 사용할 수 있는 커넥션이 없을 때 커넥션을 얻기 위해 기다리는 최대 시간
  - 참고: HikariCP의 기본 대기 시간은 30초

대시기간이 길면 유저가 최대 30초까지 기다려야할 수도 있다는 의미이다. 이에 따라 커넥션 대기시간은 짧게(0.5~3초)로 유지하자.

시나리오1
1. 대기시간이 길 때 서버가 처리할 수 있는 처리량을 초과하는 요청이 들어올 경우,
2. 대기하고 있는 유저들이 취소후 재요청
3. 애플리케이션은 기존 요청을 즉시 취소하지 않기 때문에 기존요청+새로운요청 을 대기하고 있음

해결방법
- 커넥션 대기시간을 짧게 설정한다

#### 설정3. 최대 유휴 시간, 유효성 검사, 최대 유지 시간

최대 유휴 시간: 사용되지 않는 커넥션을 풀에 유지할 수 있는 최대 시간
- DB에 설정된 비활성화 유지 시간보다 짧게 설정하면 DB가 연결을 끊기전에 커넥션을 풀에서 제거할 수 있다 

유효성 검사: 커넥션이 정상적으로 사용가능한 상태인지 확인하는 절차
- 커넥션풀의 구현에 따라 커넥션을 가져올 때 검사하거나 주기적으로 커넥션풀을 검사할 수 있다

### 적중률과 삭제 규칙 (캐시)
- 캐시는 메모리가 무한이 아니다
- 따라서 주기적으로 삭제를 해줘야하는데 삭제 규칙은 보통 아래와 같다
  - LRU(Least Recently Used): 가장 오랫동안 사용되지 않은 데이터 삭제  
  - LFU(Least Frequently Used): 가장 적게 사용된 데이터 삭제
  - FIFO(First In First Out): 먼저 추가된 데이터를 먼저 삭제
- 최신 데이터를 자주 사용하는 경향이 있기 때문에 오래된 데이터는 주기적으로 삭제하도록 한다

### 로컬 캐시와 리모트 캐시
- 로컬 캐시: 서버 메모리에서 사용하는 캐시
  - 빠르게 접근할 수 있지만 여러서버가 존재할 경우 서버별로 캐시데이터가 다를 수 있다
- 리모트 캐시 : 원격 서버에서 사용하는 캐시
  - 로컬 캐시보단 느리지만 캐시크기를 유연하게 가져갈 수 있다

### 캐시 사전 적재 (캐시 워밍)
- 트래픽이 순간적으로 급증하는 패턴을 보이면 캐시를 미리 밀어넣는 것도 고려할 수 있다

### 캐시 무효화
- 유효하지 않는 캐시는 적절한 시점에 삭제해줘야한다
- 민감한 내용에 대해 변경이 생기면 그 즉시 캐시는 무효화해야한다

### 가비지 컬렉터와 메모리 사용
가비지컬렉터: 정해진 규칙에 따라 사용하지 않는 메모리를 찾아 삭제

- 메모리 사용을 줄이면 GC 시간도 줄어들 가능이 높다
  - 검사해야할 메모리 수가 줄어들기 때문이다
  - 실제 메모리 사용 패턴에 맞게 최대 힙 크기를 조정해야한다
- 한 번에 대량으로 객체를 생성하는 것을 주의하자 
  - 대량의 객체가 생성되는 것을 방지하려면 조회 범위를 제한해야한다 
- 파일 다운로드 같은 기능을 구현할 때는 스트림을 활용한다

### 응답 데이터 압축 
- HTML, CSS, JS, JSON 같은 텍스트 데이터는 압축을 하면 효율성이 크게 증가한다
  - gzip으로 줄이면 70% 이상 데이터가 압축되며 그만큼 전송시간도 빨라진다
  - jpeg나 zip파일 처럼 이미 압축한 데이터는 다시 앞축해도 효과가 없다.
  - 웹 서버에서 압축을 했더라도 방화벽이 이를 해제해 응답할 수 있다
  - AWS같은 클라우드 서비스는 트래픽 규모가 커질수록 데이터 응답 크기를 줄이는 것이 비용절감에 도움이 된다

### 정적 자원과 브라우저 캐시 
서버 응답자원은 1.동적자원 2.정적자원으로 나뉜다
- 이미지나 JS같은 크기가 큰 파일은 캐싱하면 효율이 좋다 
- 정적자원 캐시는 2가지가 존재한다.
  - 1. 브라우저캐시: 브라우저에 저장하고 사용하기 때문에 빠르지만 브라우저별로 동작하기 때문에 트래픽이 증가하면 서버 부하가 늘어난다
  - 2. 컨텐츠 전송 네트워크(CDN): CDN서비스를 이용하기 때문에 서버는 한번만 처리를 하고 나머지는 CDN 서버에서 자원을 서빙해준다.
