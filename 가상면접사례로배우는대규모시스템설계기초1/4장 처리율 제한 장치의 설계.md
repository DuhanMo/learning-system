# 4장 처리율 제한 장치의 설계

처리율 제한 장치(rate limiter)란? 네트워크 시스템에서 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어하기 위한 장치.

**사례** 

- 사용자는 초당 2회 이상 새 글 작성 불가
- 동일 IP로 하루에 10개 이상의 계정 생성 불가
- 동일 디바이스로 주 5회 이상 리워드 요청 불가

API에 처리율 제한 장치를 두었을 때 장점

- DOS(Denial of Service)공격에 의한 자원 고갈 방지
- 외부 API호출시 과금이 되는 경우라면 비용 절감 가능
- 서버 과부하 방지

## 1단계 문제 이해 및 설계 범위 확정

면접관과 소통 예시

- 어떤 종류의 처리율 제한 장치를 설계해야 하는지?
- 어떤 기준을 사용해서 API 호출을 제어해야 하는지?
- 시스템 규모는 어느 정도여야 하는지?
- 시스템이 분산 환경에서 동작해야 하는지?
- 처리율 제한 장치는 독립된 서비스인지, 애플리에키션 코드에 포함되어야 하는지?
- 사용자의 요청이 처리율 제한 요청에 거절된 경우 사용자에게 알려야 하는지?

### 요구사항

시스템 요구사항 요약

- 설정된 처리율을 초과하는 요청은 정확히 제한
- 낮은 응답시간
- 가능한 적은 메모리 사용
- 분산형 처리율 제한: 하나의 장치를 여러 서버나 프로세스에서 공유할 수 있어야 함
- 예외 처리
- 높은 결함 감내성

## 2단계 개략적 설계안 제시 및 동의 구하기

### 처리율 제한 장치는 어디에 둘 것인가?

클라이언트 측: 쉽게 위변조 가능

서버 측: 서버에 둘 수 있고 미들웨어로 둘 수 있음

클라우드 마이크로 서비스 → 처리율 제한 장치는 보통 **API 게이트웨이**라고 불리는 컴포넌트에 구현, 클라우드 업체가 유지 보수를 담당하는 서비스

API 게이트 웨이: 처리율 제한을 지원하는 미들웨어

처리율 제한 장치를 어디에 두어야하는지 적용될 수 있는 지침

- 프로그래밍 언어, 캐시 서비스 등 현재 사용중인 기술 스택을 점검
- 비즈니스에 맞는 처리율 제한 알고리즘 확인
- 사용자 인증, IP 허용 목록 관리 등을 처리하기 위한 API 게이트웨이가 이미 있는지 확인
- 처리율 제한 서비스 직접 구현시에는 시간이 소요된다는 점을 인지

### 처리율 제한 알고리즘

- 토큰 버킷
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터

**토큰 버킷 알고리즘**

동작원리

- 토큰 버킷은 지정된 용량을 가지는 컨테이너
    - 주기적으로 토큰이 채워짐
    - 토큰이 꽉찬 버킷에는 더이상 토큰이 추가되지 않음
- 각 요청이 처리 될대마다 하나의 토큰 사용
    - 토큰이 충분할 경우 요청을 시스템에 전달
    - 토큰이 없는 경우 해당 요청을 버림
- 토큰 버킷 알고리즘은 2개의 인자를 받음
    - 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
    - 토큰 공급률: 버킷에 공급되는 초당 토큰 개수

사용해야 하는 버킷 개수

- 통상적으로 API 엔드포인트마다 별도의 버킷 적용
    - 사용자가 하루에 한번 포스팅할 수 있고, 150명까지 친구 추가할수 있고, 다섯번의 좋아요만 누를 수 있다면 사용자마다 3개의 버킷 할당
- IP 주소별로 처리율 제한을 두어야 하는 경우, IP 주소마다 버킷 할당
- 시스템의 처리율을 초당 10,000개 요청으로 제한한다면, 하나의 버킷 할당 후 모든 요청이 해당 버킷 공유

장점

- 쉬운 구현
- 효율적인 메모리 사용
- 단시간 집중 트래픽 처리 가능

단점

- 까다로운 버킷 크기와 토큰 공급률 튜닝

**누출 버킷 알고리즘**

요청 처리율이 고정되어 있고 보통 FIFO 사용

동작원리

- 요청이 도착한 경우 큐가 가득차있는지 확인, 큐가 비어있는 경우 큐에 요청 추가
- 큐가 차있는 경우 새 요청 버림
- 지정된 시간마다 큐에서 요청을 꺼내어 처리
- 누출 버킷 알고리즘은 2개의 인자를 받음
    - 버킷 크기: 큐 사이즈와 동일한 값
    - 처리율: 지정된 시간당 항목을 처리할지 지정하는 값

장점

- 제한된 큐의 크기로 인한 효율적인 메모리 사용
- 고정된 처리율로 인한 안정적 출력

단점

- 트래픽이 몰리는 경우 큐에 요청들이 쌓이고 최신 요청들은 버려짐
- 까다로운 버킷 크기와 처리율 튜닝

**고정 윈도 카운터 알고리즘**

동작원리

- 타임라인을 고정된 간격의 윈도우로 나누고, 각 윈도마다 카운터를 붙임
- 요청이 접수될 때마다 카운터의 값 1씩 증가
- 카운터가 임계치에 도달하면 이후 요청은 새 윈도가 열릴 때까지 버려짐

장점

- 효율적인 메모리 사용
- 쉬운 이해
- 윈도가 닫히는 시점에 카운터를 초기화하여 특정한 트래픽 패턴을 처리하기에 적합

단점

- 윈도 경계 부근에 많은 트래픽이 온다면 할당된 양보다 많은 요청이 처리될 수 있음

**이동 윈도 로깅 알고리즘**

동작원리

- 요청의 타임스탬프를 추적
- 새로운 요청이 온 경우 만료된 타임스탬프 제거
- 새 요청의 타임스탬프를 로그에 추가
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달, 그렇지 않은 경우 처리를 거부

장점

- 처리율 제한 메커니즘의 정교함

단점

- 거부된 요청의 타임스탬프 보관으로 인한 다량의 메모리 사용

**이동 윈도 카운터 알고리즘**

동작원리

- 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도 값을 카운트로 이용

장점

- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하여 몰리는 트래픽에 대응 가능
- 효율적인 메모리 사용

단점

- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하므로 다소 느슨

### 개략적인 아키텍처

카운터를 메모리에 보관

레디스의 명령어

- INCR: 메모리에 저장된 카운터 값을 1 증가
- EXPIRE: 카운터에 타임아웃 값 설정

동작원리

- 클라이언트가 처리율 제한 미들웨어에게 요청 전송
- 처리율 제한 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와서 한도에 도달했는지 검사

## 3단계 상세 설계

개략적 설계에서 알 수없는 아래 항목을 설계

- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장하는지?
    - 처리율 제한 규칙은 보통 설정 파일 형태로 디스크에 저장
- 처리가 제한된 요청은 어떻게 처리되는가?
    - API는 HTTP 429(too many requests) 응답
    - 한도에 걸린 요청은 추후 처리를 위해 큐에 보관할 수 있음

**처리율 제한 장치가 사용하는 헤더**

아래와 같은 헤더를 사용할 수 있다.

- X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청의 수
- X-Ratelimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
- X-Ratelimit-Retry-After: 한도 제한에 걸리지 않기 위해 재전송 까지 남은 시간

**상세 설계**

- 처리율 제한 규칙은 디스크에 보관후 프로세스는 수시로 디스크에서 캐시로 저장
- 클라이언트 요청이 처리율 제한 미들웨어에 도달
- 처리율 제한 미들웨어는 규칙을 캐시에서 조회, 카운터 및 마지막 요청의 타임스탬프를 레디스에서 추출

**분산 환경에서의 처리율 제한 장치의 구현**

아래 문제 발생

- 경쟁 조건
- 동기화

**경쟁 조건**

2개 서버가 동시에 레디스에 저장된 카운터를 가져온 후 동시에 갱신을 하게 되면 정상적으로 갱신이 안되는 경우 발생

해결방법

- 락: 시스템 성능이 낮아지는 문제
- 루아 스크립트
- 레디스의 정렬 집합

**동기화 이슈**

처리율  제한 장치가 여러 대 일 때 클라이언트 별로 요청이 뒤바꼈을 경우 문제 발생

해결방법

- 고정 세션(sticky session): 규모면에서 확장가능하지 않고 유연하지 않음
- 레디스와 같은 중앙 집중형 데이터 저장소 사용

**성능 최적화**

- 여러 데이터 센터를 지원할 때에는 에지 서버를 심어 사용
- 제한 장치 간 데이터 동기화 시 최종 일관성 모델을 사용

**모니터링**

모니터링을 통해 아래 항목을 확인

- 채텍된 처리율 제한 알고리즘이 효과적인지
- 정의한 처리율 제한 규칙이 효과적인지

## 4단계 마무리

다뤘던 알고리즘

- 토큰 버킷
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터
- 위 알고리즘들을 구현하는 아키텍처
- 분산환경에서의 처리율 제한 장치
- 성능 최적화와 모니터링

**이 후 다뤄볼만한 항목**

- 경성 또는 연성 처리율 제한
    - 경성 처리율 제한: 요청의 개수는 임계치를 절대 넘어설 수 없음
    - 연성 처리율 제한: 요청 개수는 잠시 동안 임계치를 넘어설 수 있음
- 다양한 계층에서의 처리율 제한
    - iptable 사용 가능
- 처리율 제한을 회피하는 방법
    - 클라이언트 측 캐시를 사용하여 API 호출 횟수 감소
    - 처리율 제한 임계치를 확인 후 너무 많은 메시지 요청 방지
    - 예외나 에러 처리 코드를 도입하여 클라이언트가 예외적 상황으로부터 우아하게 복구할 수 있게 적용
    - 재시도 로직 구현시 충분한 백오프 시간 두기